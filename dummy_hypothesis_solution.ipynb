{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eccae3",
   "metadata": {},
   "source": [
    "# Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b823433",
   "metadata": {},
   "source": [
    "## Introduction and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c822d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:24.755699Z",
     "iopub.status.busy": "2022-05-23T12:02:24.755019Z",
     "iopub.status.idle": "2022-05-23T12:02:25.024863Z",
     "shell.execute_reply": "2022-05-23T12:02:25.025289Z"
    }
   },
   "outputs": [],
   "source": [
    "#: Import numerical and plotting libraries\n",
    "import numpy as np\n",
    "# Print to four digits of precision\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c823ed",
   "metadata": {},
   "source": [
    "This exercise returns to the psychopathy of students from Berkeley and MIT.  It continues from the `on_dummies` exercise.  Make sure you have done that exercise before doing this one.\n",
    "\n",
    "Here are the psychopathy questionnaire scores from another set of 5 students\n",
    "from Berkeley and MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faaefa69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.029915Z",
     "iopub.status.busy": "2022-05-23T12:02:25.029304Z",
     "iopub.status.idle": "2022-05-23T12:02:25.031163Z",
     "shell.execute_reply": "2022-05-23T12:02:25.031575Z"
    }
   },
   "outputs": [],
   "source": [
    "ucb_psycho = np.array([2.9277, 9.7348, 12.1932, 12.2576, 5.4834])\n",
    "n_ucb = len(ucb_psycho)\n",
    "mit_psycho = np.array([7.2937, 11.1465, 13.5204, 15.053, 12.6863])\n",
    "n_mit = len(mit_psycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb05dc6",
   "metadata": {},
   "source": [
    "$\\newcommand{\\yvec}{\\vec{y}}$\n",
    "\n",
    "The `psychopathy` values will be our `y` vector $\\yvec$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb77f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.037016Z",
     "iopub.status.busy": "2022-05-23T12:02:25.036370Z",
     "iopub.status.idle": "2022-05-23T12:02:25.039299Z",
     "shell.execute_reply": "2022-05-23T12:02:25.039713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Give name Y to psychopathy, for reading convenience.\n",
    "Y = np.concatenate([ucb_psycho, mit_psycho])\n",
    "# Call the number of observations \"n\"\n",
    "n = len(Y)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2504d3e",
   "metadata": {},
   "source": [
    "We  use the general linear model to do a two-level (UCB, MIT) single factor\n",
    "(college) analysis of variance on these data.\n",
    "\n",
    "Our model is that the Berkeley student data are drawn from some distribution\n",
    "with a mean value that is characteristic for Berkeley: $y_i = \\mu_{Berkeley} +\n",
    "e_i$ where $i$ corresponds to a student from Berkeley.  There is also a\n",
    "characteristic but possibly different mean value for MIT: $\\mu_{MIT}$:\n",
    "\n",
    "$$\n",
    "\\newcommand{\\xvec}{\\vec{x}}\n",
    "\\newcommand{\\evec}{\\vec{\\varepsilon}}\n",
    "\\newcommand{\\Xmat}{\\boldsymbol X}\n",
    "\\newcommand{\\bvec}{\\vec{\\beta}}\n",
    "\\newcommand{\\bhat}{\\hat{\\bvec}}\n",
    "\\newcommand{\\yhat}{\\hat{\\yvec}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_i = \\mu_{Berkeley} + e_i  \\space\\mbox{if}\\space 1 \\le i \\le 5 \\\\\n",
    "y_i = \\mu_{MIT} + e_i \\space\\mbox{if}\\space 6 \\le i \\le 10\n",
    "$$\n",
    "\n",
    "Here is the design matrix for this ANOVA, with dummy variables corresponding to\n",
    "the UCB and MIT student groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62c9874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.044742Z",
     "iopub.status.busy": "2022-05-23T12:02:25.043986Z",
     "iopub.status.idle": "2022-05-23T12:02:25.046603Z",
     "shell.execute_reply": "2022-05-23T12:02:25.047018Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Create design matrix for UCB / MIT ANOVA\n",
    "X = np.zeros((n, 2))\n",
    "X[:n_ucb, 0] = 1  # UCB indicator\n",
    "X[n_ucb:, 1] = 1  # MIT indicator\n",
    "# Show the result\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9e5db6",
   "metadata": {},
   "source": [
    "The betas are given by:\n",
    "\n",
    "$$\n",
    "\\bhat = (\\Xmat^T \\Xmat){-1}\\Xmat^T \\yvec\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0de4ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.051309Z",
     "iopub.status.busy": "2022-05-23T12:02:25.050654Z",
     "iopub.status.idle": "2022-05-23T12:02:25.053280Z",
     "shell.execute_reply": "2022-05-23T12:02:25.053709Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate transpose of design matrix multiplied by data, and therefore\n",
    "#- calculate beta vector\n",
    "B = npl.inv(X.T @ X) @ X.T @ Y\n",
    "# Show the result\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2519a",
   "metadata": {},
   "source": [
    "## Hypothesis testing with contrasts\n",
    "\n",
    "Remember the student’s t statistic from the general linear model :\n",
    "\n",
    "$$\n",
    "\\newcommand{\\cvec}{\\vec{c}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = \\frac{\\cvec^T \\bhat}\n",
    "{\\sqrt{\\hat{\\sigma}^2 \\cvec^T (\\Xmat^T \\Xmat)^+ \\cvec}}\n",
    "$$\n",
    "\n",
    "Let’s consider the top half of the t statistic, $c^T \\bhat$.\n",
    "\n",
    "Our hypothesis is that the mean psychopathy score for MIT students,\n",
    "$\\mu_{MIT}$, is higher than the mean psychopathy score for Berkeley students,\n",
    "$\\mu_{Berkeley}$.  What contrast vector $\\cvec$ do we need to apply to $\\bhat$\n",
    "to express the difference between these means?  Apply this contrast vector to\n",
    "$\\bhat$ to get the top half of the t statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef8b3c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.057972Z",
     "iopub.status.busy": "2022-05-23T12:02:25.057289Z",
     "iopub.status.idle": "2022-05-23T12:02:25.060016Z",
     "shell.execute_reply": "2022-05-23T12:02:25.060472Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Contrast vector to express difference between UCB and MIT\n",
    "#- Resulting value will be high and positive when MIT students have\n",
    "#- higher psychopathy scores than UCB students\n",
    "c = np.array([-1, 1])\n",
    "top_of_t = c @ B\n",
    "# Show the result\n",
    "top_of_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d73fe3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.064438Z",
     "iopub.status.busy": "2022-05-23T12:02:25.063753Z",
     "iopub.status.idle": "2022-05-23T12:02:25.065544Z",
     "shell.execute_reply": "2022-05-23T12:02:25.065990Z"
    }
   },
   "outputs": [],
   "source": [
    "assert top_of_t > 0, 'Oops, did you subtract the wrong value?'\n",
    "assert np.isclose(top_of_t, np.mean(mit_psycho) - np.mean(ucb_psycho))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11d885",
   "metadata": {},
   "source": [
    "Now the bottom half of the t statistic.  Remember this is\n",
    "$\\sqrt{\\hat{\\sigma}^2 \\cvec^T (\\Xmat^T \\Xmat)^+ \\cvec}$.\n",
    "\n",
    "First we generate $\\hat{\\sigma^2}$ from the residuals of the model.\n",
    "\n",
    "Calculate the fitted values and the residuals given the $\\bhat$ that you have\n",
    "already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81800f9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.070134Z",
     "iopub.status.busy": "2022-05-23T12:02:25.069469Z",
     "iopub.status.idle": "2022-05-23T12:02:25.071992Z",
     "shell.execute_reply": "2022-05-23T12:02:25.072434Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the fitted and residual values\n",
    "fitted = X @ B\n",
    "residuals = Y - fitted\n",
    "# Show residuals\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae5f5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.076154Z",
     "iopub.status.busy": "2022-05-23T12:02:25.075515Z",
     "iopub.status.idle": "2022-05-23T12:02:25.077494Z",
     "shell.execute_reply": "2022-05-23T12:02:25.077969Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(residuals) == n\n",
    "assert np.isclose(np.mean(residuals), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a6f4a",
   "metadata": {},
   "source": [
    "We want an unbiased variance estimate for $\\hat\\sigma^2$.  See the [worked\n",
    "example of GLM](https://textbook.nipraxis.org/mean_test_example.html) page and the [unbiased variance estimate](https://textbook.nipraxis.org/hypothesis_tests.html#unbiased-variance) section for\n",
    "details.\n",
    "\n",
    "The general rule is that we divide the sum of squares by $n - m$ where $m$ is\n",
    "the number of *independent* columns in the design matrix.  Specifically, $m$\n",
    "is the [matrix rank](http://matthew-brett.github.io/teaching/matrix_rank.html) of the design $\\Xmat$.  $m$ can also be called the\n",
    "*degrees of freedom of the design*.  $n - m$ is the *degrees of freedom of the\n",
    "error* (see [unbiased variance estimate](https://textbook.nipraxis.org/hypothesis_tests.html#unbiased-variance))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e247415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.082572Z",
     "iopub.status.busy": "2022-05-23T12:02:25.081886Z",
     "iopub.status.idle": "2022-05-23T12:02:25.084516Z",
     "shell.execute_reply": "2022-05-23T12:02:25.084966Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the degrees of freedom consumed by the design.\n",
    "m = npl.matrix_rank(X)\n",
    "#- Calculate the degrees of freedom of the error.\n",
    "df_error = n - m\n",
    "# Show degrees of freedom due to error.\n",
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289f912",
   "metadata": {},
   "source": [
    "Calculate the unbiased *variance* estimate $\\hat{\\sigma^2}$ by dividing the\n",
    "sums of squares of the residuals by the degrees of freedom of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175e19f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.089010Z",
     "iopub.status.busy": "2022-05-23T12:02:25.088316Z",
     "iopub.status.idle": "2022-05-23T12:02:25.091007Z",
     "shell.execute_reply": "2022-05-23T12:02:25.091459Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate the unbiased variance estimate\n",
    "var_hat = np.sum(residuals ** 2) / df_error\n",
    "# Show the result\n",
    "var_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536240a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.095302Z",
     "iopub.status.busy": "2022-05-23T12:02:25.094662Z",
     "iopub.status.idle": "2022-05-23T12:02:25.096503Z",
     "shell.execute_reply": "2022-05-23T12:02:25.096936Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.round(var_hat, 3) == 13.049"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd40ec",
   "metadata": {},
   "source": [
    "Now the calculate second part of the t statistic denominator,  $\\cvec^T (\\Xmat^T\n",
    "\\Xmat)^+ \\cvec$. You already know that $\\Xmat^T \\Xmat$ is invertible, and you\n",
    "have its inverse above, so you can use the inverse instead of the more general\n",
    "pseudo-inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bdeae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.101226Z",
     "iopub.status.busy": "2022-05-23T12:02:25.100546Z",
     "iopub.status.idle": "2022-05-23T12:02:25.103166Z",
     "shell.execute_reply": "2022-05-23T12:02:25.103593Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate c (X.T X)^-1 c.T\n",
    "c_iXtX_ct = c @ npl.inv(X.T @ X) @ c.T\n",
    "# Show the result\n",
    "c_iXtX_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96860aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.107152Z",
     "iopub.status.busy": "2022-05-23T12:02:25.106507Z",
     "iopub.status.idle": "2022-05-23T12:02:25.108430Z",
     "shell.execute_reply": "2022-05-23T12:02:25.108853Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(c_iXtX_ct, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d1a13",
   "metadata": {},
   "source": [
    "The final deminator of the t-statistic is the square root of the estimated variance `var_hat` mutiplied by the second half you have just calculated. The t-statistic is the numerator divided by the denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d362d8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.113158Z",
     "iopub.status.busy": "2022-05-23T12:02:25.112455Z",
     "iopub.status.idle": "2022-05-23T12:02:25.115048Z",
     "shell.execute_reply": "2022-05-23T12:02:25.115583Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Calculate t-statistic\n",
    "t_stat = top_of_t / np.sqrt(var_hat * c_iXtX_ct)\n",
    "# Show the result\n",
    "t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3602c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.119164Z",
     "iopub.status.busy": "2022-05-23T12:02:25.118522Z",
     "iopub.status.idle": "2022-05-23T12:02:25.120536Z",
     "shell.execute_reply": "2022-05-23T12:02:25.120987Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.round(t_stat, 3) == 1.497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2166b7d",
   "metadata": {},
   "source": [
    "How likely is a t-statistic value this positive, or more positive, if there was in fact no underlying difference between the groups ? Use the `stats` module from `scipy` to create a\n",
    "t-distribution with `df_error` (degrees of freedom of the error).  See the\n",
    "`t_stat` function in [introduction to the general linear model](https://matthew-brett.github.io/teaching/glm_intro.html) for\n",
    "inspiration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4111be48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.124892Z",
     "iopub.status.busy": "2022-05-23T12:02:25.124275Z",
     "iopub.status.idle": "2022-05-23T12:02:25.374678Z",
     "shell.execute_reply": "2022-05-23T12:02:25.375094Z"
    }
   },
   "outputs": [],
   "source": [
    "#- Use scipy.stats to give a probability of a value as positive as the one you observe.\n",
    "import scipy.stats as sst\n",
    "tdistrib = sst.t(df_error)\n",
    "# 1 - cumulative density function (P(x <= t)\n",
    "1. - tdistrib.cdf(t_stat)\n",
    "# This is the same as the \"survival function\"\n",
    "p_val = tdistrib.sf(t_stat)\n",
    "# Show the result\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc53b61",
   "metadata": {},
   "source": [
    "Check your result against the Scipy implementation of the independent t-test.\n",
    "\n",
    "Scipy, by default, calculates the two-tailed p-value, whereas you have calculated the one-sided value.  Scipy's p value should be very close to 2 x your p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc2f8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.379784Z",
     "iopub.status.busy": "2022-05-23T12:02:25.379067Z",
     "iopub.status.idle": "2022-05-23T12:02:25.381765Z",
     "shell.execute_reply": "2022-05-23T12:02:25.382176Z"
    }
   },
   "outputs": [],
   "source": [
    "t_test_result = sst.ttest_ind(mit_psycho, ucb_psycho)\n",
    "t_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a36fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.385929Z",
     "iopub.status.busy": "2022-05-23T12:02:25.385326Z",
     "iopub.status.idle": "2022-05-23T12:02:25.387124Z",
     "shell.execute_reply": "2022-05-23T12:02:25.387533Z"
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(t_test_result.statistic, t_stat)\n",
    "assert np.isclose(t_test_result.pvalue, p_val * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84276fc2",
   "metadata": {},
   "source": [
    "## Advanced hypothesis testing: F-tests\n",
    "\n",
    "Imagine we have also measured the clammy score for the Berkeley and MIT\n",
    "students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5720a0bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T12:02:25.391213Z",
     "iopub.status.busy": "2022-05-23T12:02:25.390568Z",
     "iopub.status.idle": "2022-05-23T12:02:25.392374Z",
     "shell.execute_reply": "2022-05-23T12:02:25.392813Z"
    }
   },
   "outputs": [],
   "source": [
    "#: Clamminess of handshake for UCB and MIT students\n",
    "clammy = np.array([2.6386, 9.6094, 8.3379, 6.2871, 7.2775, 2.4787,\n",
    "                   8.6037, 12.8713, 10.4906, 5.6766])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d064d",
   "metadata": {},
   "source": [
    "We want to test whether the clammy score is useful in explaining\n",
    "the psychopathy data, over and above the students’ college affiliation.\n",
    "\n",
    "To do this, we will use an [F test](https://textbook.nipraxis.org/hypothesis_tests.html#f-tests).\n",
    "\n",
    "An F-test compares a *full model* $\\Xmat_f$ with a *reduced model* $\\Xmat_r$.\n",
    "\n",
    "In our case, $\\Xmat_f$ is the model containing the `clammy` regressor, as\n",
    "well as the two dummy columns for the UCB and MIT group means.\n",
    "\n",
    "$\\Xmat_r$ is our original model, that only contains the dummy columns for the\n",
    "UCB and MIT group means.\n",
    "\n",
    "We define $SSR(\\Xmat_r)$ and $SSR(\\Xmat_f)$ as in [hypothesis tests](https://textbook.nipraxis.org/hypothesis_tests.html).\n",
    "These are the Sums of Squares of the Residuals of the reduced and full model\n",
    "respectively.\n",
    "\n",
    "$$\n",
    "\\bhat_r = \\Xmat_r^+ \\yvec \\\\\n",
    "\\hat\\evec_r = \\yvec - \\Xmat_r \\bhat_r \\\\\n",
    "SSR(\\Xmat_r) = \\hat\\evec_r^T \\hat\\evec_r \\\\\n",
    "\\\\\n",
    "\\bhat_f = \\Xmat_f^+ \\yvec \\\\\n",
    "\\hat\\evec_f = \\yvec - \\Xmat_f \\bhat_f \\\\\n",
    "SSR(\\Xmat_f) = \\hat\\evec_f^T \\hat\\evec_f\n",
    "$$\n",
    "\n",
    "You can calculate the F statistic for adding the `clammy` regressor, by\n",
    "using these calculations and the formula for the F-test in [F tests](https://textbook.nipraxis.org/hypothesis_tests.html#f-tests).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.13.7"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
